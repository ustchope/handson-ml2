{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coated-norman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 598 ms (started: 2021-08-21 00:32:41 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blank-truth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/eat_tensorflow2_in_30_days.git (fetch)\n",
      "origin\tgit@github.com:ustchope/eat_tensorflow2_in_30_days.git (push)\n",
      "[master bba3300] 更新 ch16 #1  Aug 20, 2021\n",
      " 2 files changed, 151 insertions(+), 30 deletions(-)\n",
      " create mode 100644 ch16.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To git@github.com:ustchope/eat_tensorflow2_in_30_days.git\n",
      "   8ff74c3..bba3300  master -> master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.8 s (started: 2021-08-20 21:03:52 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb *.md\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 ch16 #1  Aug 21, 2021'\n",
    "\n",
    "git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attractive-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.98 s (started: 2021-08-21 00:32:48 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#设置使用的gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "   \n",
    "    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化 Neptune 并创建新的运行\n",
    "\n",
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(project='ustchope/tf-keras-integration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入并实例化 NeptuneCallback 并将其传递给 model.fit() 的回调参数。\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           epochs=5,\n",
    "#           batch_size=64,\n",
    "#           callbacks=[neptune_cbk])\n",
    "\n",
    "\n",
    "# 记录超参数，按照真实数据填入即可\n",
    "\n",
    "PARAMS = {'lr':0.005, \n",
    "          'momentum':0.9, \n",
    "          'epochs':10,\n",
    "          'batch_size':32}\n",
    "\n",
    "# log hyper-parameters\n",
    "run['hyper-parameters'] = PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-prairie",
   "metadata": {},
   "source": [
    "# 使用 RNN 和注意力的自然语言处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-easter",
   "metadata": {},
   "source": [
    "当艾伦图灵在 1950 年想象他著名的图灵测试时，他的目标是评估机器匹配人类智能的能力。他本可以测试很多东西，例如识别图片中的猫、下棋、作曲或逃离迷宫的能力，但有趣的是，他选择了一项语言任务。更具体地说，他设计了一个聊天机器人，能够欺骗对话者认为它是人类。这个测试确实有它的弱点：一组硬编码规则可以愚弄毫无戒心或天真的人类（例如，机器可以针对某些关键字给出模糊的预定义答案；它可以假装在开玩笑或喝醉了，以通过其最奇怪的答案；或者它可以通过用自己的问题回答难题来逃避难题），并且人类智能的许多方面都被完全忽略了（例如，解释面部表情等非语言交流的能力，或学习手动任务的能力）。但该测试确实强调了一个事实，即掌握语言可以说是智人最大的认知能力。我们可以建造一台可以读写自然语言的机器吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-contract",
   "metadata": {},
   "source": [
    "自然语言任务的常见方法是使用循环神经网络。因此，我们将继续探索 RNN（在第 15 章中介绍），从字符 RNN 开始，经过训练以预测句子中的下一个字符。这将允许我们生成一些原始文本，在这个过程中我们将看到如何在一个很长的序列上构建一个 TensorFlow 数据集。我们将首先使用一个无状态的 RNN（它在每次迭代中学习文本的随机部分，没有关于文本其余部分的任何信息），然后我们将构建一个有状态的 RNN（它保留训练迭代之间的隐藏状态并继续阅读哪里它停止了，允许它学习更长的模式）。接下来，我们将构建一个 RNN 来执行情感分析（例如，阅读电影评论并提取评分者对电影的感觉），这次将句子视为单词序列，而不是字符。然后我们将展示如何使用 RNN 来构建能够执行神经机器翻译 (NMT) 的编码器-解码器架构。为此，我们将使用 TensorFlow Addons 项目提供的 seq2seq API。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-business",
   "metadata": {},
   "source": [
    "在本章的第二部分，我们将研究注意力机制。 顾名思义，这些是神经网络组件，它们学会选择模型的其余部分在每个时间步应该关注的输入部分。 首先，我们将看到如何使用注意力来提高基于 RNN 的编码器-解码器架构的性能，然后我们将完全放弃 RNN，看看一个非常成功的仅注意力架构，称为 Transformer。 最后，我们将看看 2018 年和 2019 年 NLP 的一些最重要的进步，包括非常强大的语言模型，例如 GPT-2 和 BERT，它们都基于 Transformers。\n",
    "\n",
    "让我们从一个简单而有趣的模型开始，它可以像莎士比亚一样写作（嗯，有点）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-honolulu",
   "metadata": {},
   "source": [
    "## 使用字符 RNN 生成莎士比亚文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-halifax",
   "metadata": {},
   "source": [
    "在 2015 年一篇名为“循环神经网络的不合理有效性”的著名博客文章中，Andrej Karpathy 展示了如何训练 RNN 来预测句子中的下一个字符。 然后可以使用这个 Char-RNN 生成新颖的文本，一次一个字符。 这是 Char-RNN 模型在对莎士比亚的所有作品进行训练后生成的一小部分文本示例：\n",
    "```\n",
    "PANDARUS:\n",
    "Alas, I think he shall be come approached and the day\n",
    "When little srain would be attain’d into being never fed,\n",
    "And who is but a chain and subjects of his death,\n",
    "I should not sleep.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-soldier",
   "metadata": {},
   "source": [
    "不完全是杰作，但令人印象深刻的是，该模型仅通过学习预测句子中的下一个字符就能够学习单词、语法、正确的标点符号等。 让我们从创建数据集开始，一步一步地看看如何构建 Char-RNN。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-aquatic",
   "metadata": {},
   "source": [
    "### 创建训练数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-veteran",
   "metadata": {},
   "source": [
    "首先，让我们下载莎士比亚的所有作品，使用 Keras 方便的 get_file() 函数并从 Andrej Karpathy 的 Char-RNN 项目下载数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = \"https://homl.info/shakespeare\" # shortcut URL\n",
    "\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liable-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/public/huangwei/node34/tutorial/eat_tensorflow2_in_30_days'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.98 ms (started: 2021-08-21 03:32:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-standard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
